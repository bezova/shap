

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Explainers &mdash; SHAP latest documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="#" class="icon icon-home"> SHAP
          

          
          </a>

          
            
            
              <div class="version">
                latest
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Explainers</a></li>
<li><a class="reference internal" href="#plots">Plots</a></li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">SHAP</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> &raquo;</li>
        
      <li>Explainers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <a class="reference internal image-reference" href="_images/shap_diagram.png"><img alt="_images/shap_diagram.png" class="align-center" src="_images/shap_diagram.png" style="width: 400px;" /></a>
<p>SHAP (SHapley Additive exPlanations) is a unified approach to explain the output of any machine
learning model. SHAP connects game theory with local explanations, uniting several previous
methods and representing the only possible consistent and locally accurate additive
feature attribution method based on expectations (see the SHAP NIPS paper for details).</p>
<div class="toctree-wrapper compound">
</div>
<div class="section" id="explainers">
<h1>Explainers<a class="headerlink" href="#explainers" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="shap.TreeExplainer">
<em class="property">class </em><code class="descclassname">shap.</code><code class="descname">TreeExplainer</code><span class="sig-paren">(</span><em>model</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.TreeExplainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses the Tree SHAP method to explain the output of ensemble tree models.</p>
<p>Tree SHAP is a fast and exact (assuming the trees capture the input feature dependencies) method
to estimate SHAP values for tree models and ensembles of trees. It depends on fast C++
implementations either inside the externel model package or in the local compiled C extention.</p>
<dl class="method">
<dt id="shap.TreeExplainer.approximate_tree_shap">
<code class="descname">approximate_tree_shap</code><span class="sig-paren">(</span><em>tree</em>, <em>x</em>, <em>x_missing</em>, <em>phi</em>, <em>condition=0</em>, <em>condition_feature=0</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.TreeExplainer.approximate_tree_shap" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a simple approximation equivelent to the Saabas method.</p>
<p>It is actually slow because it is in python, but that’s fine right now since it is just used
for benchmark comparisons with Saabas. It would need to be added to tree_shap.h as C++ if we
wanted it to be high speed.</p>
<p>x_missing, condition, and condition_feature are currently not used</p>
</dd></dl>

<dl class="method">
<dt id="shap.TreeExplainer.shap_values">
<code class="descname">shap_values</code><span class="sig-paren">(</span><em>X</em>, <em>tree_limit=-1</em>, <em>approximate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.TreeExplainer.shap_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate the SHAP values for a set of samples.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">numpy.array, pandas.DataFrame or catboost.Pool (for catboost)</span></dt>
<dd>A matrix of samples (# samples x # features) on which to explain the model’s output.</dd>
<dt>tree_limit <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Limit the number of trees used by the model. By default -1 means no limit.</dd>
<dt>approximate <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>Run a faster approximate version of Tree SHAP (proposed by Saabas). Only supported for
XGBoost models right now.</dd>
</dl>
<p>For models with a single output this returns a matrix of SHAP values
(# samples x # features). Each row sums to the difference between the model output for that
sample and the expected value of the model output (which is stored as expected_value
attribute of the explainer). For models with vector outputs this returns a list
of such matrices, one for each output.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="shap.KernelExplainer">
<em class="property">class </em><code class="descclassname">shap.</code><code class="descname">KernelExplainer</code><span class="sig-paren">(</span><em>model</em>, <em>data</em>, <em>link=&lt;shap.common.IdentityLink object&gt;</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.KernelExplainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses the Kernel SHAP method to explain the output of any function.</p>
<p>Kernel SHAP is a method that uses a special weighted linear regression
to compute the importance of each feature. The computed importance values
are Shapley values from game theory and also coefficents from a local linear
regression.</p>
<dl class="docutils">
<dt>model <span class="classifier-delimiter">:</span> <span class="classifier">function or iml.Model</span></dt>
<dd>User supplied function that takes a matrix of samples (# samples x # features) and
computes a the output of the model for those samples. The output can be a vector
(# samples) or a matrix (# samples x # model outputs).</dd>
<dt>data <span class="classifier-delimiter">:</span> <span class="classifier">numpy.array or pandas.DataFrame or iml.DenseData or any scipy.sparse matrix</span></dt>
<dd>The background dataset to use for integrating out features. To determine the impact
of a feature, that feature is set to “missing” and the change in the model output
is observed. Since most models aren’t designed to handle arbitrary missing data at test
time, we simulate “missing” by replacing the feature with the values it takes in the
background dataset. So if the background dataset is a simple sample of all zeros, then
we would approximate a feature being missing by setting it to zero. For small problems
this background dataset can be the whole training set, but for larger problems consider
using a single reference value or using the kmeans function to summarize the dataset.
Note: for sparse case we accept any sparse matrix but convert to lil format for
performance.</dd>
<dt>link <span class="classifier-delimiter">:</span> <span class="classifier">“identity” or “logit”</span></dt>
<dd>A generalized linear model link to connect the feature importance values to the model
output. Since the feature importance values, phi, sum up to the model output, it often makes
sense to connect them to the ouput with a link function where link(outout) = sum(phi).
If the model output is a probability then the LogitLink link function makes the feature
importance values have log-odds units.</dd>
</dl>
<dl class="method">
<dt id="shap.KernelExplainer.shap_values">
<code class="descname">shap_values</code><span class="sig-paren">(</span><em>X</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.KernelExplainer.shap_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate the SHAP values for a set of samples.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">numpy.array or pandas.DataFrame or any scipy.sparse matrix</span></dt>
<dd>A matrix of samples (# samples x # features) on which to explain the model’s output.</dd>
<dt>nsamples <span class="classifier-delimiter">:</span> <span class="classifier">“auto” or int</span></dt>
<dd>Number of times to re-evaluate the model when explaining each prediction. More samples
lead to lower variance estimates of the SHAP values.</dd>
<dt>l1_reg <span class="classifier-delimiter">:</span> <span class="classifier">“auto” or float</span></dt>
<dd>The l1 regularization to use for feature selection (the estimation procedure is based on
a debiased lasso). Set this to zero to remove the feature selection step before estimation.</dd>
</dl>
<p>For models with a single output this returns a matrix of SHAP values
(# samples x # features). Each row sums to the difference between the model output for that
sample and the expected value of the model output (which is stored as expected_value
attribute of the explainer). For models with vector outputs this returns a list
of such matrices, one for each output.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="shap.DeepExplainer">
<em class="property">class </em><code class="descclassname">shap.</code><code class="descname">DeepExplainer</code><span class="sig-paren">(</span><em>model</em>, <em>data</em>, <em>session=None</em>, <em>learning_phase_flags=None</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.DeepExplainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Meant to approximate SHAP values for deep learning models.</p>
<p>This is an enhanced version of the DeepLIFT algorithm (Deep SHAP) where, similar to Kernel SHAP, we
approximate the conditional expectations of SHAP values using a selection of background samples.
Lundberg and Lee, NIPS 2017 showed that the per node attribution rules in DeepLIFT (Shrikumar,
Greenside, and Kundaje, arXiv 2017) can be chosen to approximate Shapley values. By integrating
over many backgound samples DeepExplainer estimates approximate SHAP values such that they sum
up to the difference between the expected model output on the passed background samples and the
current model output (f(x) - E[f(x)]). Using tf.gradients to implement the backgropagation was
inspired by the gradient based implementation approach proposed by Ancona et al, ICLR 2018. Note
that this package does not currently use the reveal-cancel rule for ReLu units proposed in DeepLIFT.</p>
<dl class="method">
<dt id="shap.DeepExplainer.custom_grad">
<code class="descname">custom_grad</code><span class="sig-paren">(</span><em>op</em>, <em>*grads</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.DeepExplainer.custom_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Passes a gradient op creation request to the correct handler.</p>
</dd></dl>

<dl class="method">
<dt id="shap.DeepExplainer.phi_symbolic">
<code class="descname">phi_symbolic</code><span class="sig-paren">(</span><em>i</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.DeepExplainer.phi_symbolic" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the SHAP value computation graph for a given model output.</p>
</dd></dl>

<dl class="method">
<dt id="shap.DeepExplainer.run">
<code class="descname">run</code><span class="sig-paren">(</span><em>out</em>, <em>model_inputs</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.DeepExplainer.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs the model while also setting the learning phase flags to False.</p>
</dd></dl>

<dl class="method">
<dt id="shap.DeepExplainer.shap_values">
<code class="descname">shap_values</code><span class="sig-paren">(</span><em>X</em>, <em>ranked_outputs=None</em>, <em>output_rank_order='max'</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.DeepExplainer.shap_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Return approximate SHAP values for the model applied to the data given by X.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">list, numpy.array, or pandas.DataFrame</span></dt>
<dd>A tensor (or list of tensors) of samples (where X.shape[0] == # samples) on which to
explain the model’s output.</dd>
<dt>ranked_outputs <span class="classifier-delimiter">:</span> <span class="classifier">None or int</span></dt>
<dd>If ranked_outputs is None then we explain all the outputs in a multi-output model. If
ranked_outputs is a positive integer then we only explain that many of the top model
outputs (where “top” is determined by output_rank_order). Note that this causes a pair
of values to be returned (shap_values, indexes), where shap_values is a list of numpy
arrays for each of the output ranks, and indexes is a matrix that indicates for each sample
which output indexes were choses as “top”.</dd>
<dt>output_rank_order <span class="classifier-delimiter">:</span> <span class="classifier">“max”, “min”, or “max_abs”</span></dt>
<dd>How to order the model outputs when using ranked_outputs, either by maximum, minimum, or
maximum absolute value.</dd>
</dl>
<p>For a models with a single output this returns a tensor of SHAP values with the same shape
as X. For a model with multiple outputs this returns a list of SHAP value tensors, each of
which are the same shape as X. If ranked_outputs is None then this list of tensors matches
the number of model outputs. If ranked_outputs is a positive integer a pair is returned
(shap_values, indexes), where shap_values is a list of tensors with a length of
ranked_outputs, and indexes is a matrix that indicates for each sample which output indexes
were chosen as “top”.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="plots">
<h1>Plots<a class="headerlink" href="#plots" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="shap.summary_plot">
<code class="descclassname">shap.</code><code class="descname">summary_plot</code><span class="sig-paren">(</span><em>shap_values</em>, <em>features=None</em>, <em>feature_names=None</em>, <em>max_display=None</em>, <em>plot_type='dot'</em>, <em>color=None</em>, <em>axis_color='#333333'</em>, <em>title=None</em>, <em>alpha=1</em>, <em>show=True</em>, <em>sort=True</em>, <em>color_bar=True</em>, <em>auto_size_plot=True</em>, <em>layered_violin_max_num_bins=20</em>, <em>class_names=None</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.summary_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a SHAP summary plot, colored by feature values when they are provided.</p>
<dl class="docutils">
<dt>shap_values <span class="classifier-delimiter">:</span> <span class="classifier">numpy.array</span></dt>
<dd>Matrix of SHAP values (# samples x # features)</dd>
<dt>features <span class="classifier-delimiter">:</span> <span class="classifier">numpy.array or pandas.DataFrame or list</span></dt>
<dd>Matrix of feature values (# samples x # features) or a feature_names list as shorthand</dd>
<dt>feature_names <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>Names of the features (length # features)</dd>
<dt>max_display <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>How many top features to include in the plot (default is 20, or 7 for interaction plots)</dd>
<dt>plot_type <span class="classifier-delimiter">:</span> <span class="classifier">“dot” (default) or “violin”</span></dt>
<dd>What type of summary plot to produce</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="shap.dependence_plot">
<code class="descclassname">shap.</code><code class="descname">dependence_plot</code><span class="sig-paren">(</span><em>ind</em>, <em>shap_values</em>, <em>features</em>, <em>feature_names=None</em>, <em>display_features=None</em>, <em>interaction_index='auto'</em>, <em>color='#1E88E5'</em>, <em>axis_color='#333333'</em>, <em>dot_size=16</em>, <em>alpha=1</em>, <em>title=None</em>, <em>show=True</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.dependence_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a SHAP dependence plot, colored by an interaction feature.</p>
<dl class="docutils">
<dt>ind <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Index of the feature to plot.</dd>
<dt>shap_values <span class="classifier-delimiter">:</span> <span class="classifier">numpy.array</span></dt>
<dd>Matrix of SHAP values (# samples x # features)</dd>
<dt>features <span class="classifier-delimiter">:</span> <span class="classifier">numpy.array or pandas.DataFrame</span></dt>
<dd>Matrix of feature values (# samples x # features)</dd>
<dt>feature_names <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>Names of the features (length # features)</dd>
<dt>display_features <span class="classifier-delimiter">:</span> <span class="classifier">numpy.array or pandas.DataFrame</span></dt>
<dd>Matrix of feature values for visual display (such as strings instead of coded values)</dd>
<dt>interaction_index <span class="classifier-delimiter">:</span> <span class="classifier">“auto”, None, or int</span></dt>
<dd>The index of the feature used to color the plot.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="shap.force_plot">
<code class="descclassname">shap.</code><code class="descname">force_plot</code><span class="sig-paren">(</span><em>base_value</em>, <em>shap_values</em>, <em>features=None</em>, <em>feature_names=None</em>, <em>out_names=None</em>, <em>link='identity'</em>, <em>plot_cmap='RdBu'</em>, <em>matplotlib=False</em>, <em>show=True</em>, <em>figsize=(20</em>, <em>3)</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.force_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Visualize the given SHAP values with an additive force layout.</p>
</dd></dl>

<dl class="function">
<dt id="shap.image_plot">
<code class="descclassname">shap.</code><code class="descname">image_plot</code><span class="sig-paren">(</span><em>shap_values</em>, <em>x</em>, <em>labels=None</em>, <em>show=True</em><span class="sig-paren">)</span><a class="headerlink" href="#shap.image_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Plots SHAP values for image inputs.</p>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Scott Lundberg

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'./',
              VERSION:'latest',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
    

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>